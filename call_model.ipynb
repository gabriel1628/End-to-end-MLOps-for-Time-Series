{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "from preprocessing.preprocessing import *\n",
    "preprocessing_version = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"lightgbm\"\n",
    "preprocessing_version = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a terminal, run:\n",
    "```\n",
    "mlflow server --host 127.0.0.1 --port 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessing version 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/Documents/Git/End-to-end MLOps for Time Series/.venv/lib/python3.10/site-packages/mlforecast/core.py:455: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feat_name] = feat_vals[restore_idxs]\n",
      "/Users/gabriel/Documents/Git/End-to-end MLOps for Time Series/.venv/lib/python3.10/site-packages/mlforecast/core.py:455: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feat_name] = feat_vals[restore_idxs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (944799, 99)\n",
      "y shape : (944799,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/consumption.csv\")\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "print(f\"Using preprocessing version {preprocessing_version}\")\n",
    "preprocessing = vars()[f\"preprocessing_{preprocessing_version}\"]\n",
    "X, y = preprocessing(df)\n",
    "print(f\"X shape : {X.shape}\")\n",
    "print(f\"y shape : {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fdadf4822da4f0c8b7820b75e80c565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.592949529294766, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.592949529294766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([254.6388213])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri = 'runs:/4cfa339502cf4aafa1e30dd3c623fd6e/lgbm'\n",
    "loaded_model = mlflow.lightgbm.load_model(model_uri)\n",
    "loaded_model.predict(X[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID : 847028692385838956\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment_name = f\"Enefit {model_name} Preprocessing {preprocessing_version}\"\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "print(f\"Run ID : {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Run ID: a991f56a0ea647c58b111bac380b7877\n"
     ]
    }
   ],
   "source": [
    "# Fetch the most recent run\n",
    "runs = client.search_runs([experiment_id], order_by=[\"start_time DESC\"], max_results=10)\n",
    "# runs[0].to_dictionary()[\"data\"][\"metrics\"]#[\"test_mae\"]\n",
    "if runs:\n",
    "    latest_run_id = runs[0].info.run_id\n",
    "    print(f\"Latest Run ID: {latest_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"mlflow models serve -m ./mlartifacts/847028692385838956/a991f56a0ea647c58b111bac380b7877/artifacts/lightgbm -p 5001\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the below command in a new window. You must be in the same repo as your mlruns directory and have mlflow installed :\n",
      "    \n",
      "    mlflow models serve -m ./mlartifacts/847028692385838956/a991f56a0ea647c58b111bac380b7877/artifacts/lightgbm -p 1234\n"
     ]
    }
   ],
   "source": [
    "PORT = 1234\n",
    "print(\n",
    "    f\"\"\"Run the below command in a new window. You must be in the same repo as your mlruns directory and have mlflow installed :\n",
    "\n",
    "    mlflow models serve -m ./mlartifacts/{experiment_id}/{latest_run_id}/artifacts/lightgbm -p {PORT}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# address = \"127.0.0.1\"\n",
    "# address = \"3.252.192.81\"\n",
    "address = \"ec2-54-228-144-127.eu-west-1.compute.amazonaws.com\"\n",
    "port = 5000\n",
    "endpoint = \"api/predict\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Welcome to the homepage ! To get your energy forecasts, send your data to the /predict endpoint\n"
     ]
    }
   ],
   "source": [
    "url = f\"http://{address}:{port}/\"\n",
    "r = requests.get(url)\n",
    "print(r)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./data_json_mlforecast.json\", \"r\") as f:\n",
    "  data_json = json.load(f)\n",
    "\n",
    "url = f\"http://{address}:{port}/{endpoint}\"\n",
    "r = requests.post(url, headers={\"Content-Type\": \"application/json\"}, json=data_json)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"building_id\": 0,\n",
      "            \"datetime\": \"2023-04-02 01:00:00\",\n",
      "            \"forecasts\": [\n",
      "                922.1976036213131,\n",
      "                932.5123610370592,\n",
      "                931.3136118408446,\n",
      "                931.8626423393976,\n",
      "                933.6663574538877,\n",
      "                904.9021517636521,\n",
      "                848.4160493733832,\n",
      "                718.1604980591101,\n",
      "                585.8916252077718,\n",
      "                471.4598847224826,\n",
      "                363.03707176313384,\n",
      "                321.75121793802043,\n",
      "                315.6114474026614,\n",
      "                312.5721677303937,\n",
      "                339.64221853337955,\n",
      "                416.8970230630121,\n",
      "                549.0978898258145,\n",
      "                699.4542516902336,\n",
      "                845.9908312347918,\n",
      "                964.3835680151163,\n",
      "                1002.1501024082327,\n",
      "                962.7871234020001,\n",
      "                957.7852479536697,\n",
      "                944.9739651173605\n",
      "            ]\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(r.json()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
