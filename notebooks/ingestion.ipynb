{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c0d7c2",
   "metadata": {},
   "source": [
    "# Ingestion\n",
    "\n",
    "In this notebook we are going to ingest the data from source and save it locally and in a S3 bucket.\n",
    "<br>\n",
    "To download the data, you will need to create an account on Kaggle if you don't already have one, install the Kaggle API and join the competition [Enefit - Predict Energy Behavior of Prosumers](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers). \n",
    "<br>\n",
    "Before accessing the API, you will need to authenticate using an API token.\n",
    "Follow this link if you want to learn more about the Kaggle API : https://www.kaggle.com/discussions/getting-started/524433.\n",
    "\n",
    "We'll also use boto3 to store the data on AWS S3. We'll put the data in an S3 bucket called `enefit-competition`.\n",
    "<br>\n",
    "To do so, you'll have to [install](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html) and [configure](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-quickstart.html#getting-started-quickstart-new) the aws CLI if you haven't already done it (of course, this assumes that you already have an AWS account).\n",
    "<br>\n",
    "You can also fill in the `.env` file with your AWS credentials to access you account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562c7e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading predict-energy-behavior-of-prosumers.zip to /Users/gabriel/Documents/Git/End-to-end MLOps for Time Series/notebooks\n",
      " 99%|███████████████████████████████████████▌| 230M/233M [00:13<00:00, 21.1MB/s]\n",
      "100%|████████████████████████████████████████| 233M/233M [00:13<00:00, 17.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c predict-energy-behavior-of-prosumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58893b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip data file using ZipFile\n",
    "with ZipFile(\"./predict-energy-behavior-of-prosumers.zip\", 'r') as zObject: \n",
    "\tzObject.extractall(path=\"./predict-energy-behavior-of-prosumers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5772859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete zip file\n",
    "!rm predict-energy-behavior-of-prosumers.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70534e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path):\n",
    "    try:\n",
    "        os.mkdir(dir_path)\n",
    "        print(f\"Directory '{dir_path}' created successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Directory '{dir_path}' already exists.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: Unable to create '{dir_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d967a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../data' already exists.\n",
      "Directory '../data/raw' already exists.\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data\")\n",
    "create_dir(\"../data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55163c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved ./predict-energy-behavior-of-prosumers/client.csv -> ../data/raw/client.csv\n",
      "Moved ./predict-energy-behavior-of-prosumers/weather_station_to_county_mapping.csv -> ../data/raw/weather_station_to_county_mapping.csv\n",
      "Moved ./predict-energy-behavior-of-prosumers/gas_prices.csv -> ../data/raw/gas_prices.csv\n",
      "Moved ./predict-energy-behavior-of-prosumers/forecast_weather.csv -> ../data/raw/forecast_weather.csv\n",
      "Moved ./predict-energy-behavior-of-prosumers/electricity_prices.csv -> ../data/raw/electricity_prices.csv\n",
      "Moved ./predict-energy-behavior-of-prosumers/train.csv -> ../data/raw/train.csv\n",
      "Moved ./predict-energy-behavior-of-prosumers/historical_weather.csv -> ../data/raw/historical_weather.csv\n",
      "Moved ./predict-energy-behavior-of-prosumers/county_id_to_name_map.json -> ../data/raw/county_id_to_name_map.json\n"
     ]
    }
   ],
   "source": [
    "# Move the data we are interested in to the 'data/raw/' directory\n",
    "source = \"./predict-energy-behavior-of-prosumers\"\n",
    "destination = \"../data/raw\"\n",
    "\n",
    "files = glob(os.path.join(source, '*.csv'), recursive=True)\n",
    "files.append(\"./predict-energy-behavior-of-prosumers/county_id_to_name_map.json\")\n",
    "\n",
    "# iterate on all files to move them to destination folder\n",
    "for file_path in files:\n",
    "    dst_path = os.path.join(destination, os.path.basename(file_path))\n",
    "    shutil.move(file_path, dst_path)\n",
    "    print(f\"Moved {file_path} -> {dst_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a5e3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/predict-energy-behavior-of-prosumers'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the remaining files in 'data/'\n",
    "shutil.move(\"./predict-energy-behavior-of-prosumers\", \"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: upload the data on S3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
